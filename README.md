---
license: mit
---

# _Mirage-in-the-Eyes_: Hallucination Attack on Multi-modal Large Language Models with _Only_ Attention Sink

[![License: MIT](https://img.shields.io/badge/License-MIT-g.svg)](https://opensource.org/licenses/MIT)

**NOTE**: To prevent potential harm, we release our source code only *upon request for research purposes*.

## ğŸ“– é¡¹ç›®æ¦‚è¿° (Project Overview)

**Mirage-in-the-Eyes** æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) çš„**å¹»è§‰æ”»å‡»**ç ”ç©¶é¡¹ç›®ã€‚

æœ¬é¡¹ç›®æ·±å…¥ç ”ç©¶ MLLMs çš„å†…éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ­ç¤ºå¹»è§‰é—®é¢˜çš„æ ¹æœ¬åŸå› ï¼Œæš´éœ²æŒ‡ä»¤å¾®è°ƒè¿‡ç¨‹ä¸­çš„å›ºæœ‰æ¼æ´ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¹»è§‰æ”»å‡»æ–¹æ³•ï¼Œåˆ©ç”¨**æ³¨æ„åŠ›æ²‰é™**è¡Œä¸ºè§¦å‘ä¸å›¾åƒ-æ–‡æœ¬ç›¸å…³æ€§æœ€å°çš„å¹»è§‰å†…å®¹ï¼Œå¯¹å…³é”®ä¸‹æ¸¸åº”ç”¨æ„æˆé‡å¤§å¨èƒã€‚

ä¸ä»¥å¾€ä¾èµ–å›ºå®šæ¨¡å¼çš„å¯¹æŠ—æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç”ŸæˆåŠ¨æ€ã€æœ‰æ•ˆä¸”é«˜åº¦å¯è¿ç§»çš„è§†è§‰å¯¹æŠ—è¾“å…¥ï¼Œè€Œä¸ä¼šç‰ºç‰²æ¨¡å‹å“åº”çš„è´¨é‡ã€‚åœ¨ 6 ä¸ªçŸ¥å MLLMs ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ”»å‡»åœ¨ç ´åå…·æœ‰å¹¿æ³›é˜²å¾¡æœºåˆ¶çš„é»‘ç›’ MLLMs æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä»¥åŠå¯¹ GPT-4o å’Œ Gemini 1.5 ç­‰æœ€å…ˆè¿›å•†ä¸š API çš„è‰¯å¥½æ•ˆæœã€‚

### å·¥ä½œæµç¨‹

æœ¬é¡¹ç›®çš„å®Œæ•´å·¥ä½œæµç¨‹åˆ†ä¸ºä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 1: å¯¹æŠ—æ”»å‡»                           â”‚
â”‚                   [attack.py]                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¾“å…¥: åŸå§‹å›¾ç‰‡ (image.jpg)                                   â”‚
â”‚    â†“                                                         â”‚
â”‚  1. è¯»å–åŸå§‹å›¾ç‰‡                                              â”‚
â”‚  2. ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ (åˆ©ç”¨æ³¨æ„åŠ›æµç¨‹)                             â”‚
â”‚  3. è¾“å‡º: å¯¹æŠ—å›¾ç‰‡ (adv_image.png)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 2: æè¿°ç”Ÿæˆ                           â”‚
â”‚                   [generate.py]                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è·¯å¾„ A (Baseline):                                          â”‚
â”‚    åŸå§‹å›¾ç‰‡ â†’ æ¨¡å‹æ¨ç† â†’ åŸå§‹æè¿°                             â”‚
â”‚                                                              â”‚
â”‚  è·¯å¾„ B (Hallucinated):                                      â”‚
â”‚    å¯¹æŠ—å›¾ç‰‡ â†’ æ¨¡å‹æ¨ç† â†’ å¯¹æŠ—åæè¿°                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 3: æ•ˆæœè¯„ä¼°                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¯¹æ¯”åˆ†æ:                                                    â”‚
â”‚    â€¢ åŸå§‹æè¿° (baseline)   â†â†’   å¯¹æŠ—åæè¿° (hallucinated)    â”‚
â”‚    â€¢ è¯„ä¼°å¹»è§‰è¯±å¯¼æˆåŠŸç‡                                       â”‚
â”‚    â€¢ åˆ†ææ³¨æ„åŠ›åç§»ç¨‹åº¦                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®è„šæœ¬è¯´æ˜**:
- **`attack.py`**: ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–æ“çºµæ¨¡å‹æ³¨æ„åŠ›æœºåˆ¶
- **`generate.py`**: å¯¹åŸå§‹å›¾ç‰‡å’Œå¯¹æŠ—å›¾ç‰‡åˆ†åˆ«ç”Ÿæˆæè¿°æ–‡æœ¬
- **å¯¹æ¯”è¯„ä¼°**: é€šè¿‡æ¯”è¾ƒä¸¤ç»„æè¿°ï¼ŒéªŒè¯å¹»è§‰æ”»å‡»çš„æœ‰æ•ˆæ€§

> [!NOTE]
> **å¤ç°èŒƒå›´**ï¼šç”±äº RTX 4060 (8GB) æ˜¾å­˜é™åˆ¶ï¼Œæœ¬æŒ‡å—ä»…å¤ç° **MiniGPT-4 (Vicuna-7B)** éƒ¨åˆ†ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)

### æ€»ä½“æ­¥éª¤

| é˜¶æ®µ | å†…å®¹ |
|------|------|
| **é˜¶æ®µ 0** | [ä¸‹è½½é¡¹ç›®æ¨¡å‹](#é˜¶æ®µ-0-ä¸‹è½½é¡¹ç›®æ¨¡å‹-download-project-model) |
| **é˜¶æ®µ 1** | [ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…](#é˜¶æ®µ-1-ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…) |
| **é˜¶æ®µ 2** | [ä¸‹è½½æ¨¡å‹æƒé‡](#é˜¶æ®µ-2-ä¸‹è½½æ¨¡å‹æƒé‡-download-model-weights) |
| **é˜¶æ®µ 3** | [ä¿®æ”¹é…ç½®æ–‡ä»¶](#é˜¶æ®µ-3-ä¿®æ”¹é…ç½®æ–‡ä»¶-configuration) |
| **é˜¶æ®µ 4** | [å‡†å¤‡æ•°æ®é›†](#é˜¶æ®µ-4-å‡†å¤‡æ•°æ®é›†-data-preparation) |
| **é˜¶æ®µ 5** | [è¿è¡ŒéªŒè¯](#é˜¶æ®µ-5-è¿è¡ŒéªŒè¯-running--verification) |

---

## é˜¶æ®µ 0: ä¸‹è½½é¡¹ç›®æ¨¡å‹ (Download Project Model)

### ä» HuggingFace ä¸‹è½½

```powershell
# å®‰è£… git-lfsï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰
powershell -ExecutionPolicy ByPass -c "irm https://hf.co/cli/install.ps1 | iex"

# å…‹éš†ä»“åº“ï¼ˆåŒ…å«ä»£ç ä½†ä¸åŒ…å«å¤§æ–‡ä»¶ï¼‰
hf download RachelHGF/Mirage-in-the-Eyes
```

> [!IMPORTANT]
> å…‹éš†åè¯·æ£€æŸ¥é¡¹ç›®ç»“æ„æ˜¯å¦å®Œæ•´ï¼Œç¡®ä¿åŒ…å«ä»¥ä¸‹å…³é”®ç›®å½•ï¼š
> - `minigpt4/` - æ ¸å¿ƒä»£ç 
> - `eval/` - è¯„ä¼°è„šæœ¬
> - `eval_configs/` - é…ç½®æ–‡ä»¶
> - `transformers-4.29.2/` - ä¿®æ”¹ç‰ˆ transformers
> - `attack.py` - æ”»å‡»è„šæœ¬
> - `generate.py` - ç”Ÿæˆè„šæœ¬
> - `requirements.txt` - ä¾èµ–æ–‡ä»¶

---


## é˜¶æ®µ 1: ç¯å¢ƒé…ç½®ä¸ä¾èµ–å®‰è£…


### ğŸ› ï¸ æ–¹æ³• A: è‡ªåŠ¨åŒ–å®‰è£… (æ¨è)
æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ Windows 11 å’Œ RTX 4060 (8GB) ä¼˜åŒ–çš„è‡ªåŠ¨é…ç½®è„šæœ¬ï¼Œå¯å®ç°ä¸€é”®å®‰è£…ã€‚è¯·æŸ¥çœ‹[setup_windows.bat](setup_windows.bat)ã€‚

#### è„šæœ¬åŠŸèƒ½è¯´æ˜ï¼š
*   **ç¯å¢ƒæ¸…ç†**ï¼šè‡ªåŠ¨æ£€æŸ¥å¹¶åˆ é™¤æ—§çš„ `mllm` ç¯å¢ƒï¼Œé¿å…ä¾èµ–å†²çªã€‚
*   **Conda ç¯å¢ƒ**ï¼šåˆ›å»º Python 3.9.20 è™šæ‹Ÿç¯å¢ƒã€‚
*   **æ ¸å¿ƒåº“å®‰è£…**ï¼šè‡ªåŠ¨å®‰è£… PyTorch 2.0.1 + CUDA 11.8ã€‚
*   **ä¾èµ–å®‰è£…**ï¼šè‡ªåŠ¨å®‰è£… `requirements_windows.txt` åŠ `CLIP`ã€`baukit` ç­‰å¿…è¦ç»„ä»¶ã€‚
*   **æœ¬åœ°åº“å®‰è£…**ï¼šè‡ªåŠ¨å®‰è£…ä¿®æ”¹ç‰ˆçš„æœ¬åœ° `transformers` åº“ã€‚

#### ä½¿ç”¨è¯´æ˜ï¼š
1.  ä»¥ç®¡ç†å‘˜èº«ä»½æ‰“å¼€ **PowerShell**ã€‚
2.  è¿›å…¥é¡¹ç›®æ ¹ç›®å½•ï¼š`cd "D:\AI PROJEAT\mirage"`
3.  è¿è¡Œå‘½ä»¤ï¼š`.\setup_windows.bat`
4.  ç­‰å¾…è„šæœ¬å®Œæˆï¼ŒæœŸé—´è¯·ç¡®ä¿ç½‘ç»œç•…é€šï¼ˆéœ€è®¿é—® GitHubï¼‰ã€‚

---

### âŒ¨ï¸ æ–¹æ³• B: æ‰‹åŠ¨å®‰è£… (å¤‡é€‰)
å¦‚æœä½ å¸Œæœ›æ›´ç²¾ç»†åœ°æ§åˆ¶å®‰è£…è¿‡ç¨‹ï¼Œæˆ–è‡ªåŠ¨åŒ–è„šæœ¬æŠ¥é”™ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œã€‚

#### 1.1 åˆ›å»º Conda ç¯å¢ƒ
```powershell
# åˆ›å»º Python 3.9 ç¯å¢ƒ
conda create -n mllm python=3.9.20
conda activate mllm
```

#### 1.2 å®‰è£…ä¾èµ–
```powershell
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt
```

> [!CAUTION]
> **å…³äº `requirements.txt` çš„é‡è¦é¿å‘è¯´æ˜**ï¼š
> åŸå§‹é¡¹ç›®çš„ `requirements.txt` åŒ…å«äº†å¤§é‡é’ˆå¯¹ Linux æœåŠ¡å™¨ç¯å¢ƒçš„é…ç½®ï¼Œåœ¨ Windows/Win11 ä¸‹ä¼šæŠ¥é”™ï¼ŒåŸå› åŒ…æ‹¬ï¼š
> - âœ— åŒ…å« 29 ä¸ª Linux ç¡¬ç¼–ç è·¯å¾„é“¾æ¥ (`file:///home/...`)ã€‚
> - âœ— åŒ…å« Linux ä¸“ç”¨åº“ï¼ˆå¦‚ `uvloop`, `ptyprocess` ç­‰ï¼‰ã€‚
> - âœ— åŒ…å«éœ€è¦ SSH å¯†é’¥é…ç½®çš„ Git ä¾èµ–ã€‚
>
> å› æ­¤ï¼Œ**å¦‚æœä½ æ˜¯ Windows ç”¨æˆ·ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨ä¸‹æ–¹çš„ Windows ä¸“ç”¨å‘½ä»¤**ï¼Œä»¥é¿å…å®‰è£…å¤±è´¥ã€‚

> [!IMPORTANT]
> ç”±äºåŸé¡¹ç›®æ˜¯åœ¨ Linux/æœåŠ¡å™¨ç¯å¢ƒä¸Šè¿è¡Œï¼Œæˆ‘ä»¬ä¸º Win11 ä¼˜åŒ–äº†ä¾èµ–æ–‡ä»¶ï¼š[requirements_windows.txt](requirements_windows.txt)
```powershell
# å®‰è£… Windows ä¸“ç”¨ä¾èµ–
pip install -r requirements_windows.txt

# å®‰è£…ä¿®æ”¹ç‰ˆ transformers
python -m pip install -e transformers-4.29.2
```

#### 1.3 è¡¥è£…é¢å¤–ä¾èµ–
```powershell
conda activate mllm
pip install sentencepiece accelerate peft timm einops open_clip_torch opencv-python omegaconf webdataset matplotlib pandas
```

#### 1.4 éªŒè¯å®‰è£…
ä½¿ç”¨æˆ‘ä»¬ç¼–å†™çš„éªŒè¯è„šæœ¬[verify_install.py](verify_install.py)æ£€æŸ¥ç¯å¢ƒæ˜¯å¦é…ç½®æ­£ç¡®ï¼š
```powershell
python verify_install.py
```

> [!TIP]
> å¦‚æœå‡ºç°æ ¸å¿ƒé”™è¯¯ï¼Œè¯·æ£€æŸ¥ CUDA å’Œ PyTorch ç‰ˆæœ¬ã€‚
> **é‡è¦æé†’**ï¼šè™½ç„¶æ‚¨çš„æ˜¾å¡é©±åŠ¨å¯èƒ½æ”¯æŒ CUDA 12.xï¼Œä½†æœ¬é¡¹ç›®ä¾èµ– CUDA 11.x çš„ç¯å¢ƒã€‚è„šæœ¬ä¸­å·²é»˜è®¤å®‰è£… CUDA 11.8 ç‰ˆæœ¬çš„ PyTorch ä»¥ç¡®ä¿æœ€ä½³å…¼å®¹æ€§ã€‚æ¨èç¯å¢ƒï¼šCUDA 11.7+ / PyTorch 2.0+ã€‚

---

## é˜¶æ®µ 2: ä¸‹è½½æ¨¡å‹æƒé‡ (Download Model Weights)

### 2.1 Vicuna-7B-v1.5 (~13GB)

#### æ–¹å¼ 1: ä½¿ç”¨ HuggingFace CLI (æ¨è)
```powershell
# åˆ›å»ºç›®å½•
mkdir -p "D:\AI PROJEAT\mirage\weights\vicuna"

# ç™»å½• Hugging Face (é¦–æ¬¡ä½¿ç”¨éœ€è¦)
# è·å– Token é“¾æ¥: https://huggingface.co/settings/tokens
huggingface-cli login

# ä¸‹è½½æ¨¡å‹
huggingface-cli download lmsys/vicuna-7b-v1.5 --local-dir "D:\AI PROJEAT\mirage\weights\vicuna\vicuna-7b-v1.5"
```

#### æ–¹å¼ 2: æ‰‹åŠ¨ä¸‹è½½
1. è®¿é—®ï¼š[HuggingFace - Vicuna-7B-v1.5](https://huggingface.co/lmsys/vicuna-7b-v1.5)
2. åœ¨ "Files and versions" ä¸­ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ã€‚
3. ä¿å­˜è‡³ï¼š`D:\AI PROJEAT\mirage\weights\vicuna\vicuna-7b-v1.5\`

### 2.2 MiniGPT-4 é¢„è®­ç»ƒæƒé‡ (~36MB)
ä»ç½‘ç«™ä¸Šï¼ˆhttps://github.com/Vision-CAIR/MiniGPT-4?tab=readme-ov-fileï¼‰æ‰¾åˆ°ï¼Œä¸‹è½½pretrained_minigpt4_7b.pth
æˆ–è€…ç›´æ¥è®¿é—®ï¼šhttps://drive.google.com/file/d/1RY9jV0dyqLX-o38LrumkKRh6Jtaop58R/view

> [!WARNING]
> **æ˜¾å­˜é™åˆ¶æé†’**
> - RTX 4060 (8GB) ä»…æ”¯æŒ Vicuna-7B æ¨¡å‹
> - ä¸è¦ä¸‹è½½ Vicuna-13B æˆ–æ›´å¤§çš„æ¨¡å‹
> - ç¡®ä¿ä½¿ç”¨ `vicuna-7b-v1.5` å¯¹åº”çš„ 7B ç‰ˆæœ¬ä»¥èŠ‚çœæ˜¾å­˜

---

## é˜¶æ®µ 3: ä¿®æ”¹é…ç½®æ–‡ä»¶ (Configuration)

### 3.1 ä¿®æ”¹è¯„ä¼°é…ç½®

ç¼–è¾‘æ–‡ä»¶ï¼š`eval_configs/minigpt4_eval.yaml`

```yaml
# ç¬¬ 8 è¡Œä¿®æ”¹ä¸ºï¼ˆä½¿ç”¨æ­£æ–œæ  / æˆ–åŒåæ–œæ  \\ï¼‰:
ckpt: 'D:/AI PROJEAT/mirage/weights/minigpt4/pretrained_minigpt4_7b.pth'
```

### 3.2 ä¿®æ”¹æ¨¡å‹é…ç½®

ç¼–è¾‘æ–‡ä»¶ï¼š`minigpt4/configs/models/minigpt4_vicuna0.yaml`

```yaml
# ç¬¬ 18 è¡Œä¿®æ”¹ä¸º:
llama_model: "D:/AI PROJEAT/mirage/weights/vicuna/vicuna-7b-v1.5"
```

> [!TIP]
> ä½¿ç”¨ç»å¯¹è·¯å¾„å¯ä»¥é¿å…è·¯å¾„é”™è¯¯ã€‚Windows ç”¨æˆ·å¯ä»¥ä½¿ç”¨æ­£æ–œæ  `/` æˆ–åŒåæ–œæ  `\\`ã€‚

---

## é˜¶æ®µ 4: å‡†å¤‡æ•°æ®é›† (Data Preparation)

### 4.1 Hallubench æ•°æ®é›†

#### ä¸‹è½½æ–¹å¼

è®¿é—®é¡¹ç›®ç½‘ç«™ [https://huggingface.co/RachelHGF/Mirage-in-the-Eyes](https://huggingface.co/RachelHGF/Mirage-in-the-Eyes) æä¾›äº† Hallubench æ•°æ®é›†çš„ä¸‹è½½æ–¹å¼ï¼š
è®¿é—®è¿™ä¸ªåœ°å€ï¼šhttps://github.com/opendatalab/HA-DPO

ç›®å½•ç»“æ„
```powershell
data
â”œâ”€â”€ hadpo/minigpt4/
â”‚  â””â”€â”€ desc_data.json
â”‚  â””â”€â”€ pope_data.json
```

### 4.2 Visual Genome æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰

å¦‚éœ€è®­ç»ƒæˆ–å®Œæ•´å¤ç°ï¼Œè¯·ä¸‹è½½ Visual Genome æ•°æ®é›†ï¼š

**ä¸‹è½½é“¾æ¥ï¼š**
- å›¾åƒæ•°æ®é›†ï¼ˆPart 1ï¼‰: [VG_100K](https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip) (~5GB)
- å›¾åƒæ•°æ®é›†ï¼ˆPart 2ï¼‰: [VG_100K_2](https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip) (~9GB)
- å…ƒæ•°æ®: [image_data.json](http://visualgenome.org/static/data/dataset/image_data.json.zip) (~1.69MB)
- åŒºåŸŸæè¿°: [region_descriptions.json](http://visualgenome.org/static/data/dataset/region_descriptions.json.zip) (~121MB)

**ç›®å½•ç»“æ„ï¼š**

```
D:\AI PROJEAT\mirage\data\VG\
â”œâ”€â”€ VG_100K/                    # 64,346 å¼ å›¾ç‰‡
â”œâ”€â”€ VG_100K_2/                  # 43,903 å¼ å›¾ç‰‡
â”œâ”€â”€ image_data.json             # å›¾åƒå…ƒæ•°æ®
â””â”€â”€ region_descriptions.json    # åŒºåŸŸæè¿°æ•°æ®
```

---

## é˜¶æ®µ 5: è¿è¡ŒéªŒè¯ (Running & Verification)

### 5.1 å¯¹æŠ—æ”»å‡»åŸç† (Attack Mechanism)

#### æ ¸å¿ƒæ€æƒ³

**Mirage-in-the-Eyes** åˆ©ç”¨ **PGD (Projected Gradient Descent)** è¿­ä»£ä¼˜åŒ–ç®—æ³•ï¼Œåœ¨å›¾ç‰‡ä¸Šæ·»åŠ äººçœ¼éš¾ä»¥å¯Ÿè§‰çš„æ‰°åŠ¨ï¼Œé€šè¿‡æ“çºµæ¨¡å‹çš„**æ³¨æ„åŠ›æœºåˆ¶**è¯±å¯¼äº§ç”Ÿå¹»è§‰è¾“å‡ºã€‚

#### æ”»å‡»æµç¨‹

```
åŸå§‹å›¾ç‰‡ â†’ [åˆå§‹åŒ–éšæœºæ‰°åŠ¨] â†’ è¿­ä»£ä¼˜åŒ–å¾ªç¯ (30è½®)
                                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  1. å‰å‘ä¼ æ’­ (æ¨¡å‹æ¨ç†)              â”‚
         â”‚  2. æå–æ³¨æ„åŠ›çŸ©é˜µå’Œéšè—çŠ¶æ€         â”‚
         â”‚  3. è®¡ç®—æŸå¤± (æ³¨æ„åŠ›åç§»ç¨‹åº¦)        â”‚
         â”‚  4. åå‘ä¼ æ’­æ±‚æ¢¯åº¦                   â”‚
         â”‚  5. æ›´æ–°æ‰°åŠ¨: Î´ â† Î´ + Î±Â·sign(âˆ‡)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                          ä¿å­˜å¯¹æŠ—å›¾ç‰‡
```

#### å…³é”®ç»„ä»¶

| ç»„ä»¶ | ä½œç”¨ | æ˜¯å¦ä¾èµ–äºMLLM |
|------|------|---------|
| **å‰å‘ä¼ æ’­** | è·å–æ¨¡å‹å¯¹å½“å‰æ‰°åŠ¨å›¾ç‰‡çš„å“åº” | âœ… **å¿…éœ€** |
| **æ³¨æ„åŠ›æå–** | åˆ†ææ¨¡å‹æ³¨æ„åŠ›åˆ†å¸ƒ (`attentions`) | âœ… **å¿…éœ€** |
| **æŸå¤±è®¡ç®—** | è¯„ä¼°æ³¨æ„åŠ›åç§»ç¨‹åº¦ | âœ… **å¿…éœ€** |
| **åå‘ä¼ æ’­** | è®¡ç®—æŸå¤±å¯¹å›¾ç‰‡åƒç´ çš„æ¢¯åº¦ | âœ… **å¿…éœ€** |
| **æ‰°åŠ¨æ›´æ–°** | æ²¿æ¢¯åº¦æ–¹å‘ä¿®æ”¹å›¾ç‰‡ | âŒ æ— éœ€ |

> [!IMPORTANT]
> å¯¹æŠ—æ”»å‡»æ˜¯ä¸€ä¸ª**ä¼˜åŒ–é—®é¢˜**ï¼Œæ¯è½®è¿­ä»£éƒ½éœ€è¦å®Œæ•´çš„æ¨¡å‹å‰å‘+åå‘ä¼ æ’­ï¼Œ**æ— æ³•ç»•è¿‡æœ¬åœ°æ¨¡å‹**ã€‚

---

### 5.2 ç¡¬ä»¶é™åˆ¶ä¸å›°å¢ƒ (Hardware Limitations)

#### æ˜¾å­˜éœ€æ±‚åˆ†æ

å¯¹æŠ—æ”»å‡» (`attack.py`) çš„æ˜¾å­˜å ç”¨è¿œè¶…æ™®é€šæ¨ç†ï¼š

| èµ„æºç±»å‹ | å ç”¨é‡ | è¯´æ˜ |
|---------|--------|------|
| æ¨¡å‹åŠ è½½ (VIT + Q-Former + Vicuna-7B) | ~13-14 GB | åŸºç¡€å ç”¨ |
| å‰å‘ä¼ æ’­æ¿€æ´»å€¼ | ~2-3 GB | ä¸­é—´å¼ é‡ |
| åå‘ä¼ æ’­æ¢¯åº¦ | ~2-3 GB | æ¢¯åº¦å­˜å‚¨ |
| **æ€»è®¡** | **~18-20 GB** | RTX 4060 (8GB) æ— æ³•æ»¡è¶³ |

#### é‡åˆ°çš„é—®é¢˜

# æ˜¾å­˜çˆ†äº†ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼

åœ¨ **RTX 4060 (8GB)** ç¯å¢ƒä¸‹è¿è¡Œ `attack.py` ä¼šé‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

```
torch.cuda.OutOfMemoryError: CUDA out of memory. 
Tried to allocate 32.00 MiB (GPU 0; 8.00 GiB total capacity; 
14.39 GiB already allocated; 0 bytes free)
```

---

### 5.3 è§£å†³æ–¹æ¡ˆï¼šdevice_map å†…å­˜ä¼˜åŒ– (Solution: device_map Memory Optimization)

#### é—®é¢˜è¯Šæ–­

åœ¨ RTX 4060 (8GB) ç¯å¢ƒä¸‹ï¼Œå³ä½¿æ˜¯æ¨ç† (+generate.py+) ä¹Ÿå¯èƒ½é­é‡ OOMï¼š

```
Loading LLAMA...
torch.cuda.OutOfMemoryError: CUDA out of memory.
```

**æ ¹æœ¬åŸå› **ï¼šVicuna-7B æ¨¡å‹æœ¬èº«éœ€è¦çº¦ 13-14 GB æ˜¾å­˜ï¼Œè¿œè¶… 8GB å®¹é‡ã€‚

#### è§£å†³æ–¹æ¡ˆï¼šHuggingFace Accelerate çš„ +device_map+

é€šè¿‡å¯ç”¨ **device_map="auto"** å’Œ **offload_folder**ï¼Œå¯ä»¥å°†éƒ¨åˆ†æ¨¡å‹å±‚è‡ªåŠ¨åˆ†é…åˆ° CPU/ç£ç›˜ï¼š

```python
# minigpt4/models/mini_gpt4.py (å·²ä¿®æ”¹)
self.llama_model = LlamaForCausalLM.from_pretrained(
    llama_model,
    torch_dtype=torch.float16,
    device_map="auto",          # è‡ªåŠ¨åˆ†é…æ¨¡å‹å„å±‚åˆ° GPU/CPU
    offload_folder="./offload_cache",  # ä¸´æ—¶æ–‡ä»¶å¤¹ç”¨äºç£ç›˜ offload
)
```

**å·¥ä½œåŸç†**ï¼š
1.  **GPU å±‚**ï¼šå°†æ¨¡å‹çš„å‰å‡ å±‚ï¼ˆé«˜é¢‘è®¿é—®ï¼‰æ”¾åœ¨ GPU
2.  **CPU å±‚**ï¼šå°†ä¸­é—´å±‚ offload åˆ° CPU å†…å­˜
3.  **ç£ç›˜å±‚**ï¼šå°†æœ«å°¾å±‚ offload åˆ°ç£ç›˜ï¼ˆæœ€æ…¢ä½†èŠ‚çœå†…å­˜ï¼‰

#### é…ç½®æ–‡ä»¶ä¿®æ”¹

åœ¨ +eval_configs/minigpt4_eval.yaml+ ä¸­æ·»åŠ ï¼š

```yaml
model:
  arch: mini_gpt4
  # ... å…¶ä»–é…ç½® ...
  
  # æ˜¾å­˜ä¼˜åŒ–ï¼šå¯ç”¨æ¨¡å‹åˆ‡åˆ†å’Œ CPU offload
  device_map: "auto"
  offload_folder: "./offload_cache"
```

#### ä»£ç ä¿®æ”¹

ä¸ºäº†æ”¯æŒ device_mapï¼Œéœ€è¦åœ¨ +generate.py+ å’Œ +test_small_sample.py+ ä¸­æ·»åŠ æ™ºèƒ½è®¾å¤‡åˆ†é…é€»è¾‘ï¼š

```python
# æ£€æŸ¥ LLM æ˜¯å¦ä½¿ç”¨äº† device_map
llm_model = getattr(model, 'llama_model', None) or getattr(model, 'llm_model', None)

if llm_model is not None and getattr(llm_model, "hf_device_map", None) is not None:
    # LLM ä½¿ç”¨äº† device_mapï¼ˆå¯èƒ½ offload åˆ° CPU/ç£ç›˜ï¼‰
    # åªå°†è§†è§‰ç¼–ç å™¨å’Œ Q-Former æ¬åˆ° GPU
    if hasattr(model, 'visual_encoder'):
        model.visual_encoder = model.visual_encoder.to(device)
    if hasattr(model, 'ln_vision'):
        model.ln_vision = model.ln_vision.to(device)
    if hasattr(model, 'Qformer'):
        model.Qformer = model.Qformer.to(device)
    if hasattr(model, 'llama_proj'):
        model.llama_proj = model.llama_proj.to(device)
    if hasattr(model, 'query_tokens'):
        model.query_tokens.data = model.query_tokens.data.to(device)
else:
    # LLM æ²¡ç”¨ device_mapï¼Œæ•´ä½“æ¬åˆ° GPU
   model = model.to(device)
```

#### æ€§èƒ½ä¸æƒè¡¡

| æ–¹æ¡ˆ | æ¨ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ | é€‚ç”¨åœºæ™¯ |
|------|---------|---------|---------|
| **å…¨ GPU** |  æœ€å¿« |  ~14 GB | é«˜ç«¯ GPU (A100/V100) |
| **device_map (GPU+CPU)** |  è¾ƒå¿« |  ~4-6 GB | ä¸­ç«¯ GPU (RTX 3090/4090) |
| **device_map (GPU+CPU+Disk)** |  è¾ƒæ…¢ |  ~2-4 GB | **ä½ç«¯ GPU (RTX 4060 8GB)**  |

**å®æµ‹ç»“æœ**ï¼ˆRTX 4060 8GBï¼‰ï¼š
-  **+generate.py+** - æ¨ç†æˆåŠŸï¼ˆæ¯å¼ å›¾ç‰‡çº¦ 20-30 ç§’ï¼‰
-  **+test_small_sample.py+** - éªŒè¯é€šè¿‡
-  **+attack.py+** - ä»ç„¶ OOMï¼ˆè§ä¸‹æ–‡åˆ†æï¼‰

---

### 5.4 æ”»å‡»ç¨‹åºå¤±è´¥çš„æ ¹æœ¬åŸå›  (Root Cause of Attack Failure)

#### ç—‡çŠ¶ï¼šå¯¹æŠ—å›¾ç‰‡ç›®å½•ä¸ºç©º

è¿è¡Œ +attack.py+ åæ£€æŸ¥è¾“å‡ºç›®å½•ï¼š

```powershell
PS> ls outputs/minigpt4_*/adv_images/
# Empty - æ²¡æœ‰ç”Ÿæˆä»»ä½• .png æ–‡ä»¶ï¼
```

+attack.log+ ä¹Ÿæ˜¯ç©ºçš„ï¼Œè¯´æ˜æ”»å‡»è¿‡ç¨‹ä¸­é€”å¤±è´¥ä½†é”™è¯¯è¢«é™é»˜å¿½ç•¥ã€‚

#### ç›´æ¥æµ‹è¯• attack.py

```powershell
python attack.py --model minigpt4 --gpu-id 0 \
  --data-path test_attack_data.json \
  --images-path "data\VG\VG_100K" \
  --save-path "test_adv_output" \
  --generation-mode greedy --eps 2
```

**ç»“æœ**ï¼š

```
Initializing Model
Loading VIT Done
Loading Q-Former Done
Loading LLAMA Done
...
torch.cuda.OutOfMemoryError: CUDA out of memory. 
Tried to allocate 256.00 MiB (GPU 0; 8.00 GiB total capacity; 
7.89 GiB already allocated; 0 bytes free; 7.93 GiB reserved)
```

#### ä¸ºä»€ä¹ˆ device_map å¯¹æ”»å‡»æ— æ•ˆï¼Ÿ

| é˜¶æ®µ | å†…å­˜éœ€æ±‚ | device_map æ•ˆæœ |
|------|---------|----------------|
| **æ¨ç† (generate.py)** | æ¨¡å‹æƒé‡ (13-14 GB) + å‰å‘æ¿€æ´»å€¼ (1-2 GB) |  **æœ‰æ•ˆ** - å¯å°†æ¨¡å‹å±‚ offload |
| **æ”»å‡» (attack.py)** | æ¨¡å‹æƒé‡ + å‰å‘æ¿€æ´»å€¼ + **åå‘ä¼ æ’­æ¢¯åº¦** (2-3 GB) + **æ³¨æ„åŠ›å›¾** (1-2 GB) + **ä¼˜åŒ–å™¨çŠ¶æ€** (1 GB) |  **æ— æ•ˆ** - æ¢¯åº¦å’Œæ³¨æ„åŠ›å›¾å¿…é¡»åœ¨ GPU |

**å…³é”®å·®å¼‚**ï¼š

1. **æ¢¯åº¦å­˜å‚¨**ï¼šPGD æ”»å‡»éœ€è¦ä¿å­˜æ¯å±‚çš„æ¢¯åº¦ç”¨äºåå‘ä¼ æ’­
   ```python
   loss.backward()  # æ¢¯åº¦ä¼šå ç”¨å¤§é‡ GPU æ˜¾å­˜
   ```

2. **æ³¨æ„åŠ›å›¾æå–**ï¼šéœ€è¦å®Œæ•´çš„æ³¨æ„åŠ›çŸ©é˜µç”¨äºæŸå¤±è®¡ç®—
   ```python
   outputs = model.generate(..., output_attentions=True)
   attn_map = outputs.attentions  # å­˜å‚¨æ‰€æœ‰å±‚çš„æ³¨æ„åŠ›ï¼ˆå·¨å¤§ï¼‰
   ```

3. **30 è½®è¿­ä»£**ï¼šæ¯è½®éƒ½éœ€è¦å®Œæ•´çš„å‰å‘+åå‘ï¼Œç´¯ç§¯å†…å­˜å‹åŠ›

**å³ä½¿ä½¿ç”¨ device_mapï¼Œè¿™äº›ä¸­é—´å¼ é‡ä»ç„¶å¿…é¡»åœ¨ GPU ä¸Šï¼Œå¯¼è‡´ OOMã€‚**

#### ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æœ‰å‘ç°è¿™ä¸ªé—®é¢˜ï¼Ÿ

**é™é»˜å¤±è´¥æœºåˆ¶**ï¼š

1. +run_attack_pipeline.py+ è°ƒç”¨ +attack.py+ ä½œä¸ºå­è¿›ç¨‹
2. å­è¿›ç¨‹å´©æºƒ (+exit code: 1+)ï¼Œä½†çˆ¶è¿›ç¨‹æ²¡æœ‰ä¸­æ–­
3. æ”»å‡»é˜¶æ®µ"å®Œæˆ"ï¼ˆå‡æˆåŠŸï¼‰ï¼Œç»§ç»­æ‰§è¡Œç”Ÿæˆå’Œè¯„ä¼°é˜¶æ®µ
4. ç”¨æˆ·çœ‹åˆ°" æµç¨‹å®Œæˆï¼"ä½†å®é™…ä¸Šå¯¹æŠ—å›¾ç‰‡æ ¹æœ¬æ²¡ç”Ÿæˆ

**æ£€æŸ¥æ–¹æ³•**ï¼š

```powershell
# æ£€æŸ¥å¯¹æŠ—å›¾ç‰‡æ˜¯å¦çœŸçš„ç”Ÿæˆäº†
Get-ChildItem outputs\*\adv_images\*.png
# å¦‚æœä¸ºç©º  æ”»å‡»å¤±è´¥
```

#### å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼ˆå°šæœªå®ç°ï¼‰

**é€‰é¡¹ 1ï¼šå‡å°‘ä¼˜åŒ–å¤æ‚åº¦**
- å‡å°‘è¿­ä»£æ¬¡æ•°ï¼ˆ30  10ï¼‰
- ç®€åŒ–æŸå¤±å‡½æ•°ï¼ˆå»é™¤æ³¨æ„åŠ›å›¾æå–ï¼‰
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆgradient accumulationï¼‰

**é€‰é¡¹ 2ï¼šæ¨¡å‹é‡åŒ–**
- ä½¿ç”¨ 4-bit é‡åŒ– (bitsandbytes)
- ç‰ºç‰²ç²¾åº¦æ¢å–æ˜¾å­˜

**é€‰é¡¹ 3ï¼šäº‘ç«¯ GPU**
- ä½¿ç”¨ Google Colab Pro (A100 40GB)
- AWS/Azure GPU å®ä¾‹

**é€‰é¡¹ 4ï¼šåˆ†å¸ƒå¼æ”»å‡»**
- å°† 30 è½®è¿­ä»£åˆ†æˆå¤šä¸ªæ‰¹æ¬¡
- æ¯æ‰¹æ¬¡æ¸…ç©º GPU cache

